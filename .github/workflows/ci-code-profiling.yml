name: codspeed-benchmarks

on:
  push:
    branches:
      - "main" # or "master"
  pull_request:
  # `workflow_dispatch` allows CodSpeed to trigger backtest
  # performance analysis in order to generate initial data.
  workflow_dispatch:

# Use concurrency to ensure that only one instance of this workflow is running at a time
concurrency:
  group: ci-profiling-codspeed-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  benchmarks:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -el {0}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - name: Set up swap space
        uses: pierotofy/set-swap-space@v1.0
        with:
          swap-size-gb: 10

      - uses: mamba-org/setup-micromamba@v2 # https://github.com/mamba-org/setup-micromamba
        with:
          cache-environment: false
          environment-name: testing
          condarc: |
            channels:
              - conda-forge
          create-args: >-
            ada-py
            bcf-client
            numpy<2
            python=3.12
            pytest
            pytest-benchmark
            pytest-codspeed
            python-flatbuffers

      - name: Install codspeed
        run: |
          pip install pytest-codspeed

      - name: Install latest version
        run: |
          pip install -e .

#      - name: Run pytest-benchmark
#        run: pytest ./tests --ignore=./tests/fem/ --ignore=./tests/full/ --benchmark-json output.json
#
#      - name: Store benchmark result
#        uses: benchmark-action/github-action-benchmark@v1
#        with:
#          tool: 'pytest'
#          output-file-path: output.json
#          # Enable Job Summary for PRs
#          summary-always: true

      - name: Run benchmarks
        uses: CodSpeedHQ/action@v3
        with:
          token: ${{ secrets.CODSPEED_TOKEN }}
          run: bash -el -c "pytest ./tests --ignore=./tests/fem/ --ignore=./tests/full/ --codspeed"